{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfcb12a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision.models as models\n",
    "from digitModel import Model\n",
    "from datasetClass import MNISTDataset\n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0aa8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data\n",
    "df_train = pd.read_csv('digit-recognizer/train.csv')\n",
    "df_test = pd.read_csv('digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfa4985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing std and mean for image preprocessing later to improve performance\n",
    "train_data = df_train.drop('label', axis=1).values\n",
    "train_mean = train_data.mean()/255.\n",
    "train_std = train_data.std()/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2a4ab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.rand(len(df_train)) < 0.8\n",
    "df_val = df_train[~mask]\n",
    "df_train = df_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8723e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "classes = range(10)\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "                    [\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.RandomRotation(30),\n",
    "                    transforms.RandomAffine(degrees=20, translate=(0.1,0.1), scale=(0.9, 1.1)),\n",
    "                    transforms.GaussianBlur(kernel_size = 3, sigma=(0.1, 2.0)),\n",
    "                    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[train_mean], std=[train_std]),\n",
    "                    ])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "                    [\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[train_mean], std=[train_std]),\n",
    "                    ])\n",
    "test_transform = val_transform\n",
    "\n",
    "train_dataset = MNISTDataset(df_train, transform = train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,shuffle = True)\n",
    "val_dataset = MNISTDataset(df_val, transform = val_transform)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                batch_size=batch_size,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7704fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.to(device)\n",
    "criterion = nn.NLLLoss()   # with log_softmax() as the last layer, this is equivalent to cross entropy loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "488b91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "train_losses, val_losses = [], []\n",
    "train_accu, val_accu = [], []\n",
    "start_time = time.time()\n",
    "early_stop_counter = 10   # stop when the validation loss does not improve for 10 iterations to prevent overfitting\n",
    "counter = 0\n",
    "best_val_loss = float('Inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af2acacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10..  Time: 146.06s.. Training Loss: 2.211..  Training Accu: 0.188..  Val Loss: 1.615..  Val Accu: 0.672\n",
      "Epoch: 2/10..  Time: 128.24s.. Training Loss: 1.872..  Training Accu: 0.349..  Val Loss: 1.002..  Val Accu: 0.808\n",
      "Epoch: 3/10..  Time: 123.04s.. Training Loss: 1.660..  Training Accu: 0.430..  Val Loss: 0.750..  Val Accu: 0.858\n",
      "Epoch: 4/10..  Time: 140.36s.. Training Loss: 1.523..  Training Accu: 0.489..  Val Loss: 0.586..  Val Accu: 0.885\n",
      "Epoch: 5/10..  Time: 135.51s.. Training Loss: 1.403..  Training Accu: 0.529..  Val Loss: 0.471..  Val Accu: 0.907\n",
      "Epoch: 6/10..  Time: 123.80s.. Training Loss: 1.319..  Training Accu: 0.567..  Val Loss: 0.402..  Val Accu: 0.919\n",
      "Epoch: 7/10..  Time: 111.57s.. Training Loss: 1.246..  Training Accu: 0.592..  Val Loss: 0.335..  Val Accu: 0.928\n",
      "Epoch: 8/10..  Time: 108.49s.. Training Loss: 1.200..  Training Accu: 0.609..  Val Loss: 0.309..  Val Accu: 0.935\n",
      "Epoch: 9/10..  Time: 120.07s.. Training Loss: 1.131..  Training Accu: 0.632..  Val Loss: 0.272..  Val Accu: 0.939\n",
      "Epoch: 10/10..  Time: 122.62s.. Training Loss: 1.105..  Training Accu: 0.644..  Val Loss: 0.247..  Val Accu: 0.942\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    running_loss = 0\n",
    "    accuracy=0\n",
    "    # training step\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        log_ps = model(images)\n",
    "        \n",
    "        ps = torch.exp(log_ps)                \n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "      \n",
    "    # record training loss and accuracy\n",
    "    train_losses.append(running_loss/len(train_loader))\n",
    "    train_accu.append(accuracy/len(train_loader))\n",
    "    \n",
    "    \n",
    "    #validation step\n",
    "    val_loss = 0\n",
    "    accuracy=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            log_ps = model(images)\n",
    "            val_loss += criterion(log_ps, labels)\n",
    "\n",
    "            ps = torch.exp(log_ps)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "            \n",
    "    # record validation loss and accuracy\n",
    "    val_losses.append(val_loss/len(val_loader))\n",
    "    val_accu.append(accuracy/len(val_loader))\n",
    "    \n",
    "    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "          \"Time: {:.2f}s..\".format(time.time()-epoch_start_time),\n",
    "          \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "          \"Training Accu: {:.3f}.. \".format(train_accu[-1]),\n",
    "          \"Val Loss: {:.3f}.. \".format(val_losses[-1]),\n",
    "          \"Val Accu: {:.3f}\".format(val_accu[-1])\n",
    "         )\n",
    "\n",
    "    \n",
    "    #Get best run and stop if training does not improve (early_stop_counter == patience)\n",
    "    if val_losses[-1] < best_val_loss:\n",
    "        best_val_loss = val_losses[-1]\n",
    "        counter=0\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    else:\n",
    "        counter+=1\n",
    "        print('Validation loss has not improved since: {:.3f}..'.format(best_val_loss), 'Count: ', str(counter))\n",
    "        if counter >= early_stop_counter:\n",
    "            print('Early Stopping Now!!!!')\n",
    "            model.load_state_dict(best_model_wts)\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21b788f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.values\n",
    "x_test = x_test.reshape([-1, 28, 28]).astype(np.float64)\n",
    "x_test = x_test/255.\n",
    "x_test = (x_test-train_mean)/train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d7de76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.expand_dims(x_test, axis=1)\n",
    "x_test = torch.from_numpy(x_test).float().to(device)\n",
    "# x_test.shape\n",
    "x_test.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5e14961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction tensor([2, 0, 9,  ..., 3, 9, 2])\n"
     ]
    }
   ],
   "source": [
    "# prediction time!\n",
    "model.eval()   # this is needed to disable dropouts\n",
    "with torch.no_grad():    # turn off gradient computation because we don't need it for prediction\n",
    "    ps = model(x_test)\n",
    "    prediction = torch.argmax(ps, 1)\n",
    "    print('Prediction',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf48a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,1,1)\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([0, e + 2])\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(range(1, e + 2), train_losses[:e+1], 'r', label='Training Loss')\n",
    "plt.plot(range(1, e + 2), val_losses[:e+1], 'b', label='Validation Loss')\n",
    "ax.grid(linestyle='-.')\n",
    "plt.legend()\n",
    "plt.subplot(2,1,2)\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([0, e+2])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(range(1, e + 2), train_accu[:e+1], 'r', label='Training Accuracy')\n",
    "plt.plot(range(1, e + 2), val_accu[:e+1], 'b', label='Validation Accuracy')\n",
    "ax.grid(linestyle='-.')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61e15f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
